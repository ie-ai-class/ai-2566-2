{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation matrices (binary classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up\n",
    "- Breat cancer data\n",
    "- 2 classes\n",
    "- 30 features\n",
    "- SVC\n",
    "\n",
    "\n",
    "Classes:\n",
    "- `0` = Malignant - Tumor grows rapidly, invade and destroy nearby normal tissues, and spread throughout the body.\n",
    "- `1` = Benign - Tumor grows slowly and do not spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "\n",
    "# Breast cancer data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load data\n",
    "dataObj = load_breast_cancer()\n",
    "X = dataObj.data\n",
    "y = dataObj.target\n",
    "print(np.unique(y))\n",
    "print(X.shape)\n",
    "\n",
    "# Visualize with dataframe\n",
    "df = pd.DataFrame(data=X, columns=dataObj.feature_names)\n",
    "df.insert(loc=0, column='class', value=y)\n",
    "df['class'] = df['class'].map({0: dataObj.target_names[0], 1: dataObj.target_names[1]})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=1)\n",
    "\n",
    "# Constructing a pipeline object\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()),\n",
    "            ('clf', SVC(random_state=1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Training\n",
    "pipe_svc.fit(X_train, y_train)\n",
    "\n",
    "# Prediction from test data\n",
    "y_pred = pipe_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix (works but very ugly)\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[0,1])\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual plot\n",
    "sns.heatmap(confmat, annot=True, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix (more beautiful)\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(estimator=pipe_svc, X=X_test, y_true=y_test, labels=[0,1])  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note \n",
    "\n",
    "- The class 0 samples that are correctly predicted as class 0 are now in the upper left corner of the matrix. \n",
    "- In order to change the ordering, we can use the \"labels\" argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[1, 0])\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(estimator=pipe_svc, X=X_test, y_true=y_test, labels=[1,0])  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy, Precision, Recall, and F1\n",
    "\n",
    "- Be careful with the definition of \"positive\" label.  In this case, we want `0` to be positive (เป็นโรค).\n",
    "- Therefore, we need to set `pos_label=0` when calculating precision, recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score ,recall_score, f1_score\n",
    "\n",
    "# Accuracy\n",
    "ACC = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(f\"Accuracy:{ACC:6.3f}\")\n",
    "\n",
    "# Precision\n",
    "PRE = precision_score(y_true=y_test, y_pred=y_pred, pos_label=0)\n",
    "print(f\"Precision:{PRE:6.3f}\")\n",
    "\n",
    "# Recall\n",
    "REC = recall_score(y_true=y_test, y_pred=y_pred, pos_label=0)\n",
    "print(f\"Recall:{REC:6.3f}\")\n",
    "\n",
    "# F1\n",
    "F1 = f1_score(y_true=y_test, y_pred=y_pred, pos_label=0)\n",
    "print(f\"F1:{REC:6.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `precision` score in grid search\n",
    "\n",
    "- Scoring: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "- Note that when using `scoring='precision'`, default parameters will be use, which means that `pos_label=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "c_gamma_range = [0.01, 0.1, 1.0, 10.0]\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "set1 = {'clf__C': param_range, 'clf__kernel': ['linear']}\n",
    "set2 = {'clf__C': param_range, 'clf__gamma': param_range, 'clf__kernel': ['rbf']}\n",
    "param_grid = [set1, set2]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe_svc,\n",
    "                  param_grid=param_grid,\n",
    "                  # This means that pos_label=1\n",
    "                  scoring='precision',\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "                  \n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Making scorer wrapper so that we can pass the desired argument.\n",
    "scorer = make_scorer(precision_score, pos_label=0)\n",
    "\n",
    "# Grid search.\n",
    "gs = GridSearchCV(estimator=pipe_svc,\n",
    "                  param_grid=param_grid,\n",
    "                  # Use scorer here\n",
    "                  scoring=scorer,\n",
    "                  cv=10,\n",
    "                  n_jobs=-1)\n",
    "                  \n",
    "gs = gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "79088bb772545dc9740b3f6fd02f1fa74686ae15b783fc1c2abf8492adb1c7fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
